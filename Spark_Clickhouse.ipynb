{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.functions import year\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a decorator to time the function\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        end_time = time.time()\n",
    "        print(f\"{method.__name__} took: {end_time - start_time} sec\")\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clickhouse vs Postgre in data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect_clickhouse took: 0.13023877143859863 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def connect_clickhouse():\n",
    "\n",
    "    packages = [\n",
    "        \"com.clickhouse.spark:clickhouse-spark-runtime-3.4_2.12:0.8.0\",\n",
    "        \"com.clickhouse:clickhouse-client:0.7.0\",\n",
    "        \"com.clickhouse:clickhouse-http-client:0.7.0\",\n",
    "        \"org.apache.httpcomponents.client5:httpclient5:5.2.1\"\n",
    "\n",
    "    ]\n",
    "\n",
    "    spark = (SparkSession.builder\n",
    "            .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "            .getOrCreate())\n",
    "\n",
    "    # register the clickhouse catalog\n",
    "    # this makes us be able to work with multiple clickhouse databases and tables\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse\", \"com.clickhouse.spark.ClickHouseCatalog\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.host\", \"127.0.0.1\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.protocol\", \"http\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.http_port\", \"8123\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.user\", \"default\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.password\", \"\")\n",
    "    spark.conf.set(\"spark.sql.catalog.clickhouse.database\", \"movie_lens\")\n",
    "    spark.conf.set(\"spark.clickhouse.write.format\", \"json\")\n",
    "    \n",
    "    return spark\n",
    "\n",
    "spark = connect_clickhouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "|       6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|       7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|       8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|       9| Sudden Death (1995)|              Action|\n",
      "|      10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|      11|American Presiden...|Comedy|Drama|Romance|\n",
      "|      12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|      13|        Balto (1995)|Adventure|Animati...|\n",
      "|      14|        Nixon (1995)|               Drama|\n",
      "|      15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|      16|       Casino (1995)|         Crime|Drama|\n",
      "|      17|Sense and Sensibi...|       Drama|Romance|\n",
      "|      18|   Four Rooms (1995)|              Comedy|\n",
      "|      19|Ace Ventura: When...|              Comedy|\n",
      "|      20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "read_movies_from_clickhouse took: 6.299217939376831 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def read_movies_from_clickhouse(spark):\n",
    "    df = spark.sql(\"select * from clickhouse.movie_lens.movies\")\n",
    "    df.show(20)\n",
    "    \n",
    "read_movies_from_clickhouse(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|      17|   4.0|1999-12-04 02:24:37|\n",
      "|      1|      25|   1.0|1999-12-04 02:43:48|\n",
      "|      1|      29|   2.0|1999-11-22 07:36:16|\n",
      "|      1|      30|   5.0|1999-12-04 02:24:37|\n",
      "|      1|      32|   5.0|1999-11-22 07:00:58|\n",
      "|      1|      34|   2.0|1999-11-22 06:54:51|\n",
      "|      1|      36|   1.0|1999-12-04 02:23:28|\n",
      "|      1|      80|   5.0|1999-12-04 02:22:23|\n",
      "|      1|     110|   3.0|1999-11-22 07:38:39|\n",
      "|      1|     111|   5.0|1999-12-04 02:23:28|\n",
      "|      1|     161|   1.0|1999-11-22 07:39:22|\n",
      "|      1|     166|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     176|   4.0|1999-12-02 03:18:16|\n",
      "|      1|     223|   3.0|1999-12-02 04:13:30|\n",
      "|      1|     232|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     260|   5.0|1999-11-22 06:58:16|\n",
      "|      1|     302|   4.0|1999-12-04 03:34:32|\n",
      "|      1|     306|   5.0|1999-12-04 02:21:28|\n",
      "|      1|     307|   5.0|1999-12-04 03:33:27|\n",
      "|      1|     322|   4.0|1999-12-01 20:10:01|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "read_ratings_from_clickhouse took: 0.4901313781738281 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def read_ratings_from_clickhouse(spark):\n",
    "    df = spark.sql(\"select * from clickhouse.movie_lens.ratings\")\n",
    "    df.show(20)\n",
    "    \n",
    "read_ratings_from_clickhouse(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query data from Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|      17|   4.0|1999-12-04 02:24:37|\n",
      "|      1|      25|   1.0|1999-12-04 02:43:48|\n",
      "|      1|      29|   2.0|1999-11-22 07:36:16|\n",
      "|      1|      30|   5.0|1999-12-04 02:24:37|\n",
      "|      1|      32|   5.0|1999-11-22 07:00:58|\n",
      "|      1|      34|   2.0|1999-11-22 06:54:51|\n",
      "|      1|      36|   1.0|1999-12-04 02:23:28|\n",
      "|      1|      80|   5.0|1999-12-04 02:22:23|\n",
      "|      1|     110|   3.0|1999-11-22 07:38:39|\n",
      "|      1|     111|   5.0|1999-12-04 02:23:28|\n",
      "|      1|     161|   1.0|1999-11-22 07:39:22|\n",
      "|      1|     166|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     176|   4.0|1999-12-02 03:18:16|\n",
      "|      1|     223|   3.0|1999-12-02 04:13:30|\n",
      "|      1|     232|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     260|   5.0|1999-11-22 06:58:16|\n",
      "|      1|     302|   4.0|1999-12-04 03:34:32|\n",
      "|      1|     306|   5.0|1999-12-04 02:21:28|\n",
      "|      1|     307|   5.0|1999-12-04 03:33:27|\n",
      "|      1|     322|   4.0|1999-12-01 20:10:01|\n",
      "+-------+--------+------+-------------------+\n",
      "\n",
      "show_head_of_ratings took: 0.3036034107208252 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def show_head_of_ratings(spark, n_rows=20):\n",
    "    df = spark.sql(f\"select * from clickhouse.movie_lens.ratings limit {n_rows}\")\n",
    "    df.show()\n",
    "    \n",
    "show_head_of_ratings(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|      17|   4.0|1999-12-04 02:24:37|\n",
      "|      1|      25|   1.0|1999-12-04 02:43:48|\n",
      "|      1|      29|   2.0|1999-11-22 07:36:16|\n",
      "|      1|      30|   5.0|1999-12-04 02:24:37|\n",
      "|      1|      32|   5.0|1999-11-22 07:00:58|\n",
      "|      1|      34|   2.0|1999-11-22 06:54:51|\n",
      "|      1|      36|   1.0|1999-12-04 02:23:28|\n",
      "|      1|      80|   5.0|1999-12-04 02:22:23|\n",
      "|      1|     110|   3.0|1999-11-22 07:38:39|\n",
      "|      1|     111|   5.0|1999-12-04 02:23:28|\n",
      "|      1|     161|   1.0|1999-11-22 07:39:22|\n",
      "|      1|     166|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     176|   4.0|1999-12-02 03:18:16|\n",
      "|      1|     223|   3.0|1999-12-02 04:13:30|\n",
      "|      1|     232|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     260|   5.0|1999-11-22 06:58:16|\n",
      "|      1|     302|   4.0|1999-12-04 03:34:32|\n",
      "|      1|     306|   5.0|1999-12-04 02:21:28|\n",
      "|      1|     307|   5.0|1999-12-04 03:33:27|\n",
      "|      1|     322|   4.0|1999-12-01 20:10:01|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "show_head_of_ratings took: 0.362393856048584 sec\n"
     ]
    }
   ],
   "source": [
    "show_head_of_ratings(spark, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|      17|   4.0|1999-12-04 02:24:37|\n",
      "|      1|      25|   1.0|1999-12-04 02:43:48|\n",
      "|      1|      29|   2.0|1999-11-22 07:36:16|\n",
      "|      1|      30|   5.0|1999-12-04 02:24:37|\n",
      "|      1|      32|   5.0|1999-11-22 07:00:58|\n",
      "|      1|      34|   2.0|1999-11-22 06:54:51|\n",
      "|      1|      36|   1.0|1999-12-04 02:23:28|\n",
      "|      1|      80|   5.0|1999-12-04 02:22:23|\n",
      "|      1|     110|   3.0|1999-11-22 07:38:39|\n",
      "|      1|     111|   5.0|1999-12-04 02:23:28|\n",
      "|      1|     161|   1.0|1999-11-22 07:39:22|\n",
      "|      1|     166|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     176|   4.0|1999-12-02 03:18:16|\n",
      "|      1|     223|   3.0|1999-12-02 04:13:30|\n",
      "|      1|     232|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     260|   5.0|1999-11-22 06:58:16|\n",
      "|      1|     302|   4.0|1999-12-04 03:34:32|\n",
      "|      1|     306|   5.0|1999-12-04 02:21:28|\n",
      "|      1|     307|   5.0|1999-12-04 03:33:27|\n",
      "|      1|     322|   4.0|1999-12-01 20:10:01|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "show_head_of_ratings took: 0.2457127571105957 sec\n"
     ]
    }
   ],
   "source": [
    "show_head_of_ratings(spark, 7000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|      17|   4.0|1999-12-04 02:24:37|\n",
      "|      1|      25|   1.0|1999-12-04 02:43:48|\n",
      "|      1|      29|   2.0|1999-11-22 07:36:16|\n",
      "|      1|      30|   5.0|1999-12-04 02:24:37|\n",
      "|      1|      32|   5.0|1999-11-22 07:00:58|\n",
      "|      1|      34|   2.0|1999-11-22 06:54:51|\n",
      "|      1|      36|   1.0|1999-12-04 02:23:28|\n",
      "|      1|      80|   5.0|1999-12-04 02:22:23|\n",
      "|      1|     110|   3.0|1999-11-22 07:38:39|\n",
      "|      1|     111|   5.0|1999-12-04 02:23:28|\n",
      "|      1|     161|   1.0|1999-11-22 07:39:22|\n",
      "|      1|     166|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     176|   4.0|1999-12-02 03:18:16|\n",
      "|      1|     223|   3.0|1999-12-02 04:13:30|\n",
      "|      1|     232|   5.0|1999-11-22 06:54:02|\n",
      "|      1|     260|   5.0|1999-11-22 06:58:16|\n",
      "|      1|     302|   4.0|1999-12-04 03:34:32|\n",
      "|      1|     306|   5.0|1999-12-04 02:21:28|\n",
      "|      1|     307|   5.0|1999-12-04 03:33:27|\n",
      "|      1|     322|   4.0|1999-12-01 20:10:01|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_user took: 0.33332204818725586 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_user(spark, user_id):\n",
    "    df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where user_id = {user_id}\")\n",
    "    df.show()\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_user(spark, 1)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|     10|       1|   2.5|2007-01-20 10:53:51|\n",
      "|     11|       1|   3.0|1996-12-09 05:44:36|\n",
      "|     17|       1|   4.0|2002-07-22 09:42:31|\n",
      "|     19|       1|   3.0|2000-11-20 14:14:48|\n",
      "|     20|       1|   5.0|2019-03-21 23:03:50|\n",
      "|     23|       1|   3.0|2019-10-04 18:52:12|\n",
      "|     24|       1|   4.0|1999-12-16 21:15:45|\n",
      "|     28|       1|   4.0|2000-06-20 01:08:47|\n",
      "|     33|       1|   5.0|2008-11-11 07:07:49|\n",
      "|     34|       1|   4.0|2007-11-11 07:43:38|\n",
      "|     36|       1|   3.0|2015-01-10 04:42:19|\n",
      "|     37|       1|   1.0|2001-06-17 04:49:45|\n",
      "|     43|       1|   5.0|1996-06-09 19:14:09|\n",
      "|     46|       1|   4.0|2015-10-04 16:36:55|\n",
      "|     51|       1|   3.5|2006-06-27 02:14:04|\n",
      "|     54|       1|   4.0|1997-05-20 18:36:51|\n",
      "|     57|       1|   4.0|1997-01-07 03:07:11|\n",
      "|     59|       1|   4.0|2002-08-27 03:57:42|\n",
      "|     60|       1|   3.0|2015-09-02 07:16:42|\n",
      "|     62|       1|   5.0|1999-01-16 09:55:56|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_movies took: 0.29657721519470215 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_movies(spark, movie_id):\n",
    "    df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where movie_id = {movie_id}\")\n",
    "    df.show()\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_movies(spark, 1)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|          timestamp|\n",
      "+-------+--------+------+-------------------+\n",
      "|     10|       1|   2.5|2007-01-20 10:53:51|\n",
      "|     11|       1|   3.0|1996-12-09 05:44:36|\n",
      "|     17|       1|   4.0|2002-07-22 09:42:31|\n",
      "|     19|       1|   3.0|2000-11-20 14:14:48|\n",
      "|     20|       1|   5.0|2019-03-21 23:03:50|\n",
      "|     23|       1|   3.0|2019-10-04 18:52:12|\n",
      "|     24|       1|   4.0|1999-12-16 21:15:45|\n",
      "|     28|       1|   4.0|2000-06-20 01:08:47|\n",
      "|     33|       1|   5.0|2008-11-11 07:07:49|\n",
      "|     34|       1|   4.0|2007-11-11 07:43:38|\n",
      "|     36|       1|   3.0|2015-01-10 04:42:19|\n",
      "|     37|       1|   1.0|2001-06-17 04:49:45|\n",
      "|     43|       1|   5.0|1996-06-09 19:14:09|\n",
      "|     46|       1|   4.0|2015-10-04 16:36:55|\n",
      "|     51|       1|   3.5|2006-06-27 02:14:04|\n",
      "|     54|       1|   4.0|1997-05-20 18:36:51|\n",
      "|     57|       1|   4.0|1997-01-07 03:07:11|\n",
      "|     59|       1|   4.0|2002-08-27 03:57:42|\n",
      "|     60|       1|   3.0|2015-09-02 07:16:42|\n",
      "|     62|       1|   5.0|1999-01-16 09:55:56|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_movies took: 0.2729620933532715 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68997"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_movies_ids(spark, movie_ids):\n",
    "    query = \"select * from clickhouse.movie_lens.ratings where \"\n",
    "    for movie_id in movie_ids:\n",
    "        query += f\"movie_id = {movie_id} or \"\n",
    "    query = query[:-4]\n",
    "    spark.sql(query)\n",
    "    df.show()\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_movies_ids(spark, [1, 2])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complicated queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     df\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_avg_recent_ratings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mtimeit.<locals>.timed\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimed\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m      4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m took: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m, in \u001b[0;36mget_avg_recent_ratings\u001b[1;34m(spark)\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(query)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where movie_id = {movie_id}\")\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where user_id = {user_id}\")\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_avg_recent_ratings(spark):\n",
    "    query = f\"with recent_rating as (select r.user_id, r.movie_id, r.rating, r.timestamp from clickhouse.movie_lens.ratings r where r.timestamp >= (select max(timestamp) - interval 1 year from clickhouse.movie_lens.ratings)), user_activity as (select user_id, count(*) as total_rated_movie from recent_rating group by user_id) select user_id from user_activity order by total_rated_movie desc limit 10\"\n",
    "    \n",
    "    df = spark.sql(query)\n",
    "    # df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where movie_id = {movie_id}\")\n",
    "    # df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where user_id = {user_id}\")\n",
    "    df.show()\n",
    "    return df\n",
    "\n",
    "df = get_avg_recent_ratings(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|user_id|\n",
      "+-------+\n",
      "| 103013|\n",
      "| 108412|\n",
      "|  87324|\n",
      "| 161180|\n",
      "|   1668|\n",
      "|  98875|\n",
      "| 159164|\n",
      "|  22270|\n",
      "|  57389|\n",
      "|  43302|\n",
      "+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "get_avg_recent_ratings took: 253.95917391777039 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_avg_recent_ratings(spark):\n",
    "    query = f\"with recent_rating as (select r.user_id, r.movie_id, r.rating, r.timestamp from clickhouse.movie_lens.ratings r where r.timestamp >= (select max(timestamp) - interval 1 year from clickhouse.movie_lens.ratings)), user_activity as (select user_id, count(*) as total_rated_movie from recent_rating group by user_id) select user_id from user_activity order by total_rated_movie desc\"\n",
    "    \n",
    "    df = spark.sql(query)\n",
    "    # df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where movie_id = {movie_id}\")\n",
    "    # df = spark.sql(f\"select * from clickhouse.movie_lens.ratings where user_id = {user_id}\")\n",
    "    df.show(10)\n",
    "    return df\n",
    "\n",
    "df = get_avg_recent_ratings(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Apache Spark vs Pandas for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import chdb.dataframe as cdf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join in query vs join after loaded into dataframe\n",
    "\n",
    "# @timeit\n",
    "# def join_movies_ratings_query(spark):\n",
    "#     query = f\"select m.title, m.genres from clickhouse.movie_lens.movies m join clickhouse.movie_lens.ratings r on m.movie_id = r.movie_id\"\n",
    "#     df = spark.sql(query)\n",
    "#     df.show(20)\n",
    "#     return df\n",
    "\n",
    "# def join_movies_ratings_df(spark):\n",
    "#     df_movies = spark.sql(\"select * from clickhouse.movie_lens.movies\")\n",
    "#     df_ratings = spark.sql(\"select * from clickhouse.movie_lens.ratings\")\n",
    "#     df = df_movies.join(df_ratings, df_movies.movie_id == df_ratings.movie_id)\n",
    "#     df.show(20)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+---------+-------+\n",
      "|               title|              genres|userId|rating|timestamp|movieId|\n",
      "+--------------------+--------------------+------+------+---------+-------+\n",
      "|Sense and Sensibi...|       Drama|Romance|     1|   4.0|944249077|     17|\n",
      "|Leaving Las Vegas...|       Drama|Romance|     1|   1.0|944250228|     25|\n",
      "|City of Lost Chil...|Adventure|Drama|F...|     1|   2.0|943230976|     29|\n",
      "|Shanghai Triad (Y...|         Crime|Drama|     1|   5.0|944249077|     30|\n",
      "|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|     1|   5.0|943228858|     32|\n",
      "|         Babe (1995)|      Children|Drama|     1|   2.0|943228491|     34|\n",
      "|Dead Man Walking ...|         Crime|Drama|     1|   1.0|944249008|     36|\n",
      "|White Balloon, Th...|      Children|Drama|     1|   5.0|944248943|     80|\n",
      "|   Braveheart (1995)|    Action|Drama|War|     1|   3.0|943231119|    110|\n",
      "|  Taxi Driver (1976)|Crime|Drama|Thriller|     1|   5.0|944249008|    111|\n",
      "| Crimson Tide (1995)|  Drama|Thriller|War|     1|   1.0|943231162|    161|\n",
      "|Doom Generation, ...|  Comedy|Crime|Drama|     1|   5.0|943228442|    166|\n",
      "|Living in Oblivio...|              Comedy|     1|   4.0|944079496|    176|\n",
      "|       Clerks (1994)|              Comedy|     1|   3.0|944082810|    223|\n",
      "|Eat Drink Man Wom...|Comedy|Drama|Romance|     1|   5.0|943228442|    232|\n",
      "|Star Wars: Episod...|Action|Adventure|...|     1|   5.0|943228696|    260|\n",
      "|Queen Margot (Rei...|       Drama|Romance|     1|   4.0|944253272|    302|\n",
      "|Three Colors: Red...|               Drama|     1|   5.0|944248888|    306|\n",
      "|Three Colors: Blu...|               Drama|     1|   5.0|944253207|    307|\n",
      "|Swimming with Sha...|        Comedy|Drama|     1|   4.0|944053801|    322|\n",
      "+--------------------+--------------------+------+------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "load_and_join_spark took: 2.1775853633880615 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def load_and_join_spark():\n",
    "    df_ratings = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dataset/ml-32m/ratings.csv\")\n",
    "    df_movies = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dataset/ml-32m/movies.csv\")\n",
    "\n",
    "    df_joined = df_movies.join(df_ratings, df_movies.movieId == df_ratings.movieId).select(df_movies.title, df_movies.genres, df_ratings.userId, df_ratings.rating, df_ratings.timestamp, df_ratings.movieId)\n",
    "\n",
    "    df_joined.show(20)\n",
    "    return df_joined\n",
    "\n",
    "df_joined_spark = load_and_join_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timeit\n",
    "# def load_and_join_dask():\n",
    "#     df_movies = dd.read_csv(\"dataset/ml-32m/movies.csv\")\n",
    "#     df_ratings = dd.read_csv(\"dataset/ml-32m/ratings.csv\")\n",
    "#     df = dd.merge(df_movies, df_ratings, left_on=\"movieId\", right_on=\"movieId\")\n",
    "#     print(df.head(20))\n",
    "#     return df\n",
    "\n",
    "# load_and_join_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movieId             title                                       genres  \\\n",
      "0         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "1         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "2         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "3         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "4         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "5         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "6         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "7         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "8         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "9         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "10        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "11        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "12        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "13        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "14        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "15        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "16        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "17        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "18        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "19        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "\n",
      "    userId  rating   timestamp  \n",
      "0    62610     4.0   963723675  \n",
      "1    62613     4.0  1482956935  \n",
      "2    62614     5.0  1446946784  \n",
      "3    62615     4.0   853396285  \n",
      "4    62619     4.0  1610223375  \n",
      "5    62621     4.0   852764072  \n",
      "6    62623     4.5  1552818860  \n",
      "7    62624     4.0   996431190  \n",
      "8    62628     4.5  1392139309  \n",
      "9    62629     4.0  1130946329  \n",
      "10   62631     4.5  1549367376  \n",
      "11   62639     2.0  1216391775  \n",
      "12   62647     4.0  1587854229  \n",
      "13   62651     2.5  1378666699  \n",
      "14   62656     5.0   974941422  \n",
      "15   62657     5.0   874492863  \n",
      "16   62658     5.0  1002138849  \n",
      "17   62661     1.5  1294694039  \n",
      "18   62662     5.0  1586285142  \n",
      "19   62663     3.0   902958464  \n",
      "load_and_join_pandas took: 6.747288465499878 sec\n"
     ]
    }
   ],
   "source": [
    "# pandas loads and joins df > 4 times slower than spark for ddataset of 32M records\n",
    "@timeit\n",
    "def load_and_join_pandas():\n",
    "    df_ratings = pd.read_csv(\"dataset/ml-32m/ratings_chunk_2.csv\")\n",
    "    df_movies = pd.read_csv(\"dataset/ml-32m/movies.csv\")\n",
    "\n",
    "    df_joined = pd.merge(df_movies, df_ratings, on=\"movieId\")\n",
    "\n",
    "    print(df_joined.head(20))\n",
    "    return df_joined\n",
    "\n",
    "df_joined_pd = load_and_join_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rating\n",
      "movieId          \n",
      "1        4.036510\n",
      "2        3.551806\n",
      "3        3.494055\n",
      "4        3.459220\n",
      "5        3.439618\n",
      "6        3.968984\n",
      "7        3.610801\n",
      "8        3.478202\n",
      "9        3.375996\n",
      "10       3.609711\n",
      "11       3.813545\n",
      "12       3.387845\n",
      "13       3.653322\n",
      "14       3.663689\n",
      "15       3.403010\n",
      "16       3.952247\n",
      "17       4.103339\n",
      "18       3.697835\n",
      "19       3.418667\n",
      "20       3.319239\n",
      "basic_opts_pd took: 1.195014238357544 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.036510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.551806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.494055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.459220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.439618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292609</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292611</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292615</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292617</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292627</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56382 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rating\n",
       "movieId          \n",
       "1        4.036510\n",
       "2        3.551806\n",
       "3        3.494055\n",
       "4        3.459220\n",
       "5        3.439618\n",
       "...           ...\n",
       "292609   4.000000\n",
       "292611   4.000000\n",
       "292615   3.000000\n",
       "292617   3.000000\n",
       "292627   3.000000\n",
       "\n",
       "[56382 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def basic_opts_pd(df_pd):\n",
    "    df_pd = df_pd[df_pd[\"rating\"] > 2].groupby(\"movieId\").agg({\"rating\": \"mean\"})\n",
    "    print(df_pd.head(20))\n",
    "    return df_pd\n",
    "\n",
    "basic_opts_pd(df_joined_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column named \"Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-------+------+---------+----+\n",
      "|movieId|               title|              genres|userId|movieId|rating|timestamp|year|\n",
      "+-------+--------------------+--------------------+------+-------+------+---------+----+\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|     1|     17|   4.0|944249077|1995|\n",
      "|     25|Leaving Las Vegas...|       Drama|Romance|     1|     25|   1.0|944250228|1995|\n",
      "|     29|City of Lost Chil...|Adventure|Drama|F...|     1|     29|   2.0|943230976|1995|\n",
      "|     30|Shanghai Triad (Y...|         Crime|Drama|     1|     30|   5.0|944249077|1995|\n",
      "|     32|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|     1|     32|   5.0|943228858|1995|\n",
      "|     34|         Babe (1995)|      Children|Drama|     1|     34|   2.0|943228491|1995|\n",
      "|     36|Dead Man Walking ...|         Crime|Drama|     1|     36|   1.0|944249008|1995|\n",
      "|     80|White Balloon, Th...|      Children|Drama|     1|     80|   5.0|944248943|1995|\n",
      "|    110|   Braveheart (1995)|    Action|Drama|War|     1|    110|   3.0|943231119|1995|\n",
      "|    111|  Taxi Driver (1976)|Crime|Drama|Thriller|     1|    111|   5.0|944249008|1976|\n",
      "|    161| Crimson Tide (1995)|  Drama|Thriller|War|     1|    161|   1.0|943231162|1995|\n",
      "|    166|Doom Generation, ...|  Comedy|Crime|Drama|     1|    166|   5.0|943228442|1995|\n",
      "|    176|Living in Oblivio...|              Comedy|     1|    176|   4.0|944079496|1995|\n",
      "|    223|       Clerks (1994)|              Comedy|     1|    223|   3.0|944082810|1994|\n",
      "|    232|Eat Drink Man Wom...|Comedy|Drama|Romance|     1|    232|   5.0|943228442|1994|\n",
      "|    260|Star Wars: Episod...|Action|Adventure|...|     1|    260|   5.0|943228696|1977|\n",
      "|    302|Queen Margot (Rei...|       Drama|Romance|     1|    302|   4.0|944253272|1994|\n",
      "|    306|Three Colors: Red...|               Drama|     1|    306|   5.0|944248888|1994|\n",
      "|    307|Three Colors: Blu...|               Drama|     1|    307|   5.0|944253207|1993|\n",
      "|    322|Swimming with Sha...|        Comedy|Drama|     1|    322|   4.0|944053801|1995|\n",
      "+-------+--------------------+--------------------+------+-------+------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "extract_year_from_title took: 1.9304211139678955 sec\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "@timeit\n",
    "def extract_year_from_title(df):\n",
    "    df = df.withColumn(\"year\", substring(\"title\", -5, 4)).filter(col(\"year\").rlike(\"^[12]\")).withColumn(\"year\", col(\"year\").cast(\"int\"))\n",
    "    df.show(20)\n",
    "    return df\n",
    "\n",
    "df_joined_spark_with_year = extract_year_from_title(df_joined_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    movieId             title                                       genres  \\\n",
      "0         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "1         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "2         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "3         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "4         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "5         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "6         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "7         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "8         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "9         1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "10        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "11        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "12        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "13        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "14        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "15        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "16        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "17        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "18        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "19        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
      "\n",
      "    userId  rating   timestamp  year  \n",
      "0    62610     4.0   963723675  1995  \n",
      "1    62613     4.0  1482956935  1995  \n",
      "2    62614     5.0  1446946784  1995  \n",
      "3    62615     4.0   853396285  1995  \n",
      "4    62619     4.0  1610223375  1995  \n",
      "5    62621     4.0   852764072  1995  \n",
      "6    62623     4.5  1552818860  1995  \n",
      "7    62624     4.0   996431190  1995  \n",
      "8    62628     4.5  1392139309  1995  \n",
      "9    62629     4.0  1130946329  1995  \n",
      "10   62631     4.5  1549367376  1995  \n",
      "11   62639     2.0  1216391775  1995  \n",
      "12   62647     4.0  1587854229  1995  \n",
      "13   62651     2.5  1378666699  1995  \n",
      "14   62656     5.0   974941422  1995  \n",
      "15   62657     5.0   874492863  1995  \n",
      "16   62658     5.0  1002138849  1995  \n",
      "17   62661     1.5  1294694039  1995  \n",
      "18   62662     5.0  1586285142  1995  \n",
      "19   62663     3.0   902958464  1995  \n",
      "extract_year_from_title_pd took: 2.6381237506866455 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def extract_year_from_title_pd(df):\n",
    "    df[\"year\"] = df[\"title\"].str[-5:-1]\n",
    "    df = df[df[\"year\"].str.match(\"^[12]\\d{3}\")].astype({\"year\": \"int\"})     # this line takes approx 12 secs\n",
    "    print(df.head(20))\n",
    "    return df\n",
    "\n",
    "df_joined_pd_with_year = extract_year_from_title_pd(df_joined_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a movie recommender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommender = RecommendationEngine(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler(inputCols=[\"userId\", \"movieId\"], outputCol=\"features\")\n",
    "assembled_df = feature_assembler.transform(joined_df)\n",
    "(training_data, test_data) = assembled_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "lr_model = model.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------+\n",
      "|    features|rating|        prediction|\n",
      "+------------+------+------------------+\n",
      "| [19.0,12.0]|   1.0|3.5889894264465667|\n",
      "| [44.0,12.0]|   1.0|  3.58205064574231|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[571.0,12.0]|   1.0|3.4357811484965803|\n",
      "| [44.0,12.0]|   1.0|  3.58205064574231|\n",
      "|[151.0,12.0]|   3.0|3.5523526643280916|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[524.0,12.0]|   1.0| 3.448826056220583|\n",
      "| [19.0,12.0]|   1.0|3.5889894264465667|\n",
      "|[217.0,12.0]|   3.0|3.5340342832688543|\n",
      "|[274.0,12.0]|   3.5| 3.518213863263149|\n",
      "|[524.0,12.0]|   1.0| 3.448826056220583|\n",
      "|[599.0,12.0]|   1.5| 3.428009714107813|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[288.0,12.0]|   2.0|3.5143281460687654|\n",
      "|[571.0,12.0]|   1.0|3.4357811484965803|\n",
      "|[217.0,12.0]|   3.0|3.5340342832688543|\n",
      "|[288.0,12.0]|   2.0|3.5143281460687654|\n",
      "|[294.0,12.0]|   1.0| 3.512662838699744|\n",
      "|[350.0,12.0]|   3.0| 3.497119969922209|\n",
      "+------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE): 1.0392742649810824\n",
      "R2: 0.0026706517185250966\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# show predictions\n",
    "predictions.select(\"features\", \"rating\", \"prediction\").show()\n",
    "\n",
    "# evaluate the model using R2 and RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator.setMetricName(\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.546270888146419\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "ratings = joined_df.select(\"userId\", \"movieId\", \"rating\")\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# evaluate\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "# top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "\n",
    "# top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{3925, 6.7853904...|\n",
      "|     2|[{74754, 7.789781...|\n",
      "|     3|[{48322, 6.951864...|\n",
      "|     4|[{34338, 7.271497...|\n",
      "|     5|[{5034, 6.932786}...|\n",
      "|     6|[{971, 7.036011},...|\n",
      "|     7|[{4678, 9.650388}...|\n",
      "|     8|[{5055, 7.2378206...|\n",
      "|     9|[{106100, 7.42635...|\n",
      "|    10|[{2693, 8.148736}...|\n",
      "|    11|[{3200, 6.935401}...|\n",
      "|    12|[{26258, 8.614412...|\n",
      "|    13|[{2148, 7.473914}...|\n",
      "|    14|[{2906, 11.770087...|\n",
      "|    15|[{1734, 7.8901587...|\n",
      "|    16|[{3925, 5.546985}...|\n",
      "|    17|[{1658, 6.442111}...|\n",
      "|    18|[{3200, 5.1955605...|\n",
      "|    19|[{5666, 5.1309776...|\n",
      "|    20|[{179819, 7.15204...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(userRecs.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   463|[{79224, 7.039547...|\n",
      "|   496|[{34338, 9.542832...|\n",
      "|   148|[{4450, 7.3070965...|\n",
      "+------+--------------------+\n",
      "\n",
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|   463|\n",
      "|   496|\n",
      "|   148|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.show()\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[{569, 5.2485666}...|\n",
      "|   3175|[{258, 6.324589},...|\n",
      "|   2366|[{494, 7.989951},...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieSubSetRecs.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
