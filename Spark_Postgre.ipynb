{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.8.4 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 1)) (3.8.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 2)) (0.1.6)\n",
      "Requirement already satisfied: numpy==1.23.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: pymongo==4.10.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (4.10.1)\n",
      "Requirement already satisfied: pyspark==3.5.3 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (3.5.3)\n",
      "Requirement already satisfied: seaborn==0.13.2 in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: flask in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (3.1.0)\n",
      "Requirement already satisfied: flask-sqlalchemy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.8.4->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: traitlets in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib-inline==0.1.6->-r requirements.txt (line 2)) (5.14.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymongo==4.10.1->-r requirements.txt (line 4)) (2.7.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyspark==3.5.3->-r requirements.txt (line 5)) (0.10.9.7)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn==0.13.2->-r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask->-r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask->-r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask->-r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flask-sqlalchemy->-r requirements.txt (line 8)) (2.0.36)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.1.3->flask->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=3.1.2->flask->-r requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn==0.13.2->-r requirements.txt (line 6)) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn==0.13.2->-r requirements.txt (line 6)) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.4->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy->-r requirements.txt (line 8)) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy->-r requirements.txt (line 8)) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.functions import year\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a decorator to time the function\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        start_time = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        end_time = time.time()\n",
    "        print(f\"{method.__name__} took: {end_time - start_time} sec\")\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from Postgre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, download the Postgre JDBC driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect_postgre took: 7.4272308349609375 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def connect_postgre():\n",
    "    spark_postgre = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars\", \"D:\\\\projects\\\\uni_projects\\\\Big-Data\\\\Movie-Recommendation-System\\\\jars\\\\postgresql-42.7.4.jar\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", \"D:\\\\projects\\\\uni_projects\\\\Big-Data\\\\Movie-Recommendation-System\\\\jars\\\\postgresql-42.7.4.jar\") \\\n",
    "        .getOrCreate()\n",
    "    return spark_postgre\n",
    "\n",
    "spark_postgre = connect_postgre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "|       6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|       7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|       8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|       9| Sudden Death (1995)|              Action|\n",
      "|      10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|      11|American Presiden...|Comedy|Drama|Romance|\n",
      "|      12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|      13|        Balto (1995)|Adventure|Animati...|\n",
      "|      14|        Nixon (1995)|               Drama|\n",
      "|      15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|      16|       Casino (1995)|         Crime|Drama|\n",
      "|      17|Sense and Sensibi...|       Drama|Romance|\n",
      "|      18|   Four Rooms (1995)|              Comedy|\n",
      "|      19|Ace Ventura: When...|              Comedy|\n",
      "|      20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "read_movies_from_postgre took: 7.821150302886963 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def read_movies_from_postgre(spark_postgre):\n",
    "    df = spark_postgre.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"dbtable\", \"movies\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .load()\n",
    "    df.show(20)\n",
    "\n",
    "read_movies_from_postgre(spark_postgre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timeit\n",
    "# def read_ratings_from_postgre(spark_postgre):\n",
    "#     df = spark_postgre.read \\\n",
    "#         .format(\"jdbc\") \\\n",
    "#         .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "#         .option(\"dbtable\", \"ratings\") \\\n",
    "#         .option(\"user\", \"postgres\") \\\n",
    "#         .option(\"password\", \"Baotram2004\") \\\n",
    "#         .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "#         .load()\n",
    "#     try:\n",
    "#         df.show(20)\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "# read_ratings_from_postgre(spark_postgre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timeit\n",
    "# def read_ratings_from_postgre(spark_postgre):\n",
    "#     df = spark_postgre.read \\\n",
    "#         .format(\"jdbc\") \\\n",
    "#         .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "#         .option(\"dbtable\", \"ratings\") \\\n",
    "#         .option(\"user\", \"postgres\") \\\n",
    "#         .option(\"password\", \"Baotram2004\") \\\n",
    "#         .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "#         .load()\n",
    "#     try:\n",
    "#         df.head()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "# read_ratings_from_postgre(spark_postgre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query data from Postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "| 103718|     923|   2.5|1142615606|\n",
      "| 103718|     924|   4.0|1142617549|\n",
      "| 103718|     942|   4.0|1142618811|\n",
      "| 103718|     948|   4.0|1142619581|\n",
      "| 103718|     953|   4.0|1142616074|\n",
      "| 103718|     968|   4.0|1142620815|\n",
      "| 103718|     971|   3.5|1142618549|\n",
      "| 103718|    1012|   3.0|1142620685|\n",
      "| 103718|    1028|   5.0|1142619696|\n",
      "| 103718|    1035|   5.0|1142620501|\n",
      "| 103718|    1036|   2.5|1142621824|\n",
      "| 103718|    1079|   4.5|1142615841|\n",
      "| 103718|    1084|   4.0|1142615765|\n",
      "| 103718|    1094|   3.5|1142613004|\n",
      "| 103718|    1096|   4.5|1142619119|\n",
      "| 103718|    1097|   4.0|1142616475|\n",
      "| 103718|    1104|   4.0|1142616283|\n",
      "| 103718|    1120|   3.5|1142617744|\n",
      "| 103718|    1127|   2.0|1142622069|\n",
      "| 103718|    1136|   5.0|1142616019|\n",
      "+-------+--------+------+----------+\n",
      "\n",
      "query_from_postgre took: 0.3027932643890381 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, movie_id: int, rating: decimal(2,1), timestamp: bigint]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query with limit 20\n",
    "@timeit\n",
    "def query_from_postgre(spark_postgre, n_rows):\n",
    "    df = spark_postgre.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", f\"select * from ratings_temp limit {n_rows}\") \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "        \n",
    "query_from_postgre(spark_postgre, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "| 103718|     923|   2.5|1142615606|\n",
      "| 103718|     924|   4.0|1142617549|\n",
      "| 103718|     942|   4.0|1142618811|\n",
      "| 103718|     948|   4.0|1142619581|\n",
      "| 103718|     953|   4.0|1142616074|\n",
      "| 103718|     968|   4.0|1142620815|\n",
      "| 103718|     971|   3.5|1142618549|\n",
      "| 103718|    1012|   3.0|1142620685|\n",
      "| 103718|    1028|   5.0|1142619696|\n",
      "| 103718|    1035|   5.0|1142620501|\n",
      "| 103718|    1036|   2.5|1142621824|\n",
      "| 103718|    1079|   4.5|1142615841|\n",
      "| 103718|    1084|   4.0|1142615765|\n",
      "| 103718|    1094|   3.5|1142613004|\n",
      "| 103718|    1096|   4.5|1142619119|\n",
      "| 103718|    1097|   4.0|1142616475|\n",
      "| 103718|    1104|   4.0|1142616283|\n",
      "| 103718|    1120|   3.5|1142617744|\n",
      "| 103718|    1127|   2.0|1142622069|\n",
      "| 103718|    1136|   5.0|1142616019|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "query_from_postgre took: 1.1580145359039307 sec\n"
     ]
    }
   ],
   "source": [
    "df = query_from_postgre(spark_postgre, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "| 109659|     410|   3.0| 846332765|\n",
      "| 109659|     435|   3.0| 846332887|\n",
      "| 109659|     454|   3.0| 846332728|\n",
      "| 109659|     457|   2.0| 846332649|\n",
      "| 109659|     480|   3.0| 846332675|\n",
      "| 109659|     485|   3.0| 846333196|\n",
      "| 109659|     508|   3.0| 846333026|\n",
      "| 109659|     515|   3.0| 846333196|\n",
      "| 109659|     529|   3.0| 846333386|\n",
      "| 109659|     551|   3.0| 846333080|\n",
      "| 109659|     587|   3.0| 846332801|\n",
      "| 109659|     589|   3.0| 846332728|\n",
      "| 109659|     590|   3.0| 846332579|\n",
      "| 109659|     592|   3.0| 846332579|\n",
      "| 109659|     594|   3.0| 846333196|\n",
      "| 109659|     597|   3.0| 846332800|\n",
      "| 109660|     348|   3.0|1209416017|\n",
      "| 109660|     910|   4.0|1209415983|\n",
      "| 109660|    1244|   4.0|1209416086|\n",
      "| 109660|    1285|   3.5|1209415996|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "query_from_postgre took: 12.543602466583252 sec\n"
     ]
    }
   ],
   "source": [
    "df = query_from_postgre(spark_postgre, 7000000)\n",
    "# df.orderBy(\"user_id\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|      1|      17|   4.0|944249077|\n",
      "|      1|      25|   1.0|944250228|\n",
      "|      1|      29|   2.0|943230976|\n",
      "|      1|      30|   5.0|944249077|\n",
      "|      1|      32|   5.0|943228858|\n",
      "|      1|      34|   2.0|943228491|\n",
      "|      1|      36|   1.0|944249008|\n",
      "|      1|      80|   5.0|944248943|\n",
      "|      1|     110|   3.0|943231119|\n",
      "|      1|     111|   5.0|944249008|\n",
      "|      1|     161|   1.0|943231162|\n",
      "|      1|     166|   5.0|943228442|\n",
      "|      1|     176|   4.0|944079496|\n",
      "|      1|     223|   3.0|944082810|\n",
      "|      1|     232|   5.0|943228442|\n",
      "|      1|     260|   5.0|943228696|\n",
      "|      1|     302|   4.0|944253272|\n",
      "|      1|     306|   5.0|944248888|\n",
      "|      1|     307|   5.0|944253207|\n",
      "|      1|     322|   4.0|944053801|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_user took: 0.27585935592651367 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_user(spark, user_id):\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", f\"select * from ratings where user_id={user_id}\") \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_user(spark_postgre, 1)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "|  97327|       1|   4.0|1094386730|\n",
      "|  97328|       1|   4.0| 849355256|\n",
      "|  97333|       1|   4.5|1424401700|\n",
      "|  97341|       1|   3.5|1150877485|\n",
      "|  97343|       1|   5.0|1107395297|\n",
      "|  97344|       1|   3.0| 847016342|\n",
      "|  97348|       1|   3.0|1204254666|\n",
      "|  97352|       1|   4.0| 993066661|\n",
      "|  97353|       1|   5.0|1162844477|\n",
      "|  97354|       1|   4.5|1056059668|\n",
      "|  97355|       1|   5.0|1596879789|\n",
      "|  97361|       1|   2.0| 938909633|\n",
      "|  97362|       1|   3.0| 860668956|\n",
      "|  97367|       1|   5.0|1038922871|\n",
      "|  97369|       1|   4.0| 861311425|\n",
      "|  97370|       1|   3.5|1112317841|\n",
      "|  97372|       1|   3.5|1113443208|\n",
      "|  97377|       1|   3.0|1135736368|\n",
      "|  97379|       1|   5.0|1625017177|\n",
      "|  97383|       1|   4.0| 973553197|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_movies took: 1.957317590713501 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_movies(spark, movie_id):\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", f\"select * from ratings where movie_id={movie_id}\") \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_movies(spark_postgre, 1)\n",
    "# df.sort(\"user_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "|  97327|       1|   4.0|1094386730|\n",
      "|  97328|       1|   4.0| 849355256|\n",
      "|  97329|       2|   2.0| 844797324|\n",
      "|  97333|       1|   4.5|1424401700|\n",
      "|  97337|       2|   3.0| 844897034|\n",
      "|  97341|       1|   3.5|1150877485|\n",
      "|  97343|       1|   5.0|1107395297|\n",
      "|  97344|       1|   3.0| 847016342|\n",
      "|  97344|       2|   2.0| 847016692|\n",
      "|  97348|       1|   3.0|1204254666|\n",
      "|  97348|       2|   1.0|1204255277|\n",
      "|  97350|       2|   4.0| 836825763|\n",
      "|  97352|       1|   4.0| 993066661|\n",
      "|  97353|       1|   5.0|1162844477|\n",
      "|  97353|       2|   3.0|1162844374|\n",
      "|  97354|       1|   4.5|1056059668|\n",
      "|  97354|       2|   4.0|1057766202|\n",
      "|  97355|       1|   5.0|1596879789|\n",
      "|  97361|       1|   2.0| 938909633|\n",
      "|  97361|       2|   1.0| 938908216|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_ratings_by_movies took: 1.9949018955230713 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_movies(spark, movie_ids):\n",
    "    query = \"select * from ratings where \"\n",
    "    for movie_id in movie_ids:\n",
    "        query += f\"movie_id = {movie_id} or \"\n",
    "    query = query[:-4]\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", query) \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_movies(spark_postgre, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating| timestamp|\n",
      "+-------+--------+------+----------+\n",
      "| 168198|   99999|   3.0|1689394313|\n",
      "+-------+--------+------+----------+\n",
      "\n",
      "get_ratings_by_user_and_movie took: 0.22433042526245117 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_ratings_by_user_and_movie(spark, user_id, movie_id):\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", f\"select * from ratings where user_id={user_id} and movie_id={movie_id}\") \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_ratings_by_user_and_movie(spark_postgre, 168198, 99999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "WITH recent_rating AS (\n",
    "    SELECT \n",
    "        r.user_id, \n",
    "        r.movie_id, \n",
    "        r.rating, \n",
    "        r.timestamp\n",
    "    FROM \n",
    "        clickhouse.movie_lens.ratings r\n",
    "    WHERE \n",
    "        r.timestamp >= (\n",
    "            SELECT MAX(timestamp) - INTERVAL '1 year' \n",
    "            FROM clickhouse.movie_lens.ratings\n",
    "        )\n",
    "),\n",
    "user_activity AS (\n",
    "    SELECT \n",
    "        user_id, \n",
    "        COUNT(*) AS total_rated_movie\n",
    "    FROM \n",
    "        recent_rating\n",
    "    GROUP BY \n",
    "        user_id\n",
    ")\n",
    "SELECT \n",
    "    user_id \n",
    "FROM \n",
    "    user_activity \n",
    "ORDER BY \n",
    "    total_rated_movie DESC \n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|user_id|\n",
      "+-------+\n",
      "| 103013|\n",
      "| 108412|\n",
      "|  87324|\n",
      "| 161180|\n",
      "|   1668|\n",
      "|  98875|\n",
      "| 159164|\n",
      "|  22270|\n",
      "|  57389|\n",
      "|  43302|\n",
      "+-------+\n",
      "\n",
      "get_top_avg_recent_ratings took: 4.132871389389038 sec\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def get_top_avg_recent_ratings(spark):\n",
    "    query = \"with recent_rating as (select r.user_id, r.movie_id, r.rating from ratings r where to_timestamp(r.timestamp) >= (select max(to_timestamp(timestamp)) - interval '1 year' from ratings)), user_activity as (select user_id, count(*) as total_rated_movie from recent_rating group by user_id) select user_id from user_activity order by total_rated_movie desc limit 10\"\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", query) \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_top_avg_recent_ratings(spark_postgre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|user_id|\n",
      "+-------+\n",
      "| 103013|\n",
      "| 108412|\n",
      "|  87324|\n",
      "| 161180|\n",
      "|   1668|\n",
      "|  98875|\n",
      "| 159164|\n",
      "|  22270|\n",
      "|  57389|\n",
      "|  43302|\n",
      "| 100887|\n",
      "|  65925|\n",
      "| 187665|\n",
      "| 178868|\n",
      "| 108029|\n",
      "| 168198|\n",
      "| 134520|\n",
      "|  99084|\n",
      "| 181856|\n",
      "| 177834|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "get_top_avg_recent_ratings took: 3.9204039573669434 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10086"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def get_top_avg_recent_ratings(spark):\n",
    "    query = \"with recent_rating as (select r.user_id, r.movie_id, r.rating from ratings r where to_timestamp(r.timestamp) >= (select max(to_timestamp(timestamp)) - interval '1 year' from ratings)), user_activity as (select user_id, count(*) as total_rated_movie from recent_rating group by user_id) select user_id from user_activity order by total_rated_movie desc\"\n",
    "    df = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/postgres\") \\\n",
    "        .option(\"user\", \"postgres\") \\\n",
    "        .option(\"password\", \"Baotram2004\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"query\", query) \\\n",
    "        .load()\n",
    "    try:\n",
    "        df.show(20)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "df = get_top_avg_recent_ratings(spark_postgre)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Apache Spark for parallel data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------spark version: 3.5.3------------\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"Big-Data-Demo\") \\\n",
    "#     .master(\"local[*]\") \\\n",
    "#     .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "#     .config(\"spark.mongodb.read.connection.uri\", \"mongodb://127.0.0.1:27017/\")  \\\n",
    "#     .getOrCreate() \\\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Big-Data-Demo\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", \"mongodb://127.0.0.1:27017/\") \\\n",
    "    .getOrCreate() \\\n",
    "\n",
    "print(f\"----------spark version: {spark.version}------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all data from a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o120.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongo. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: mongo.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load all data from MongoDB\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_ratings \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb://127.0.0.1:27017/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatabase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mratings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m      8\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb://127.0.0.1:27017/test.movies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mload()   \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Show the loaded data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:314\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o120.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongo. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.ClassNotFoundException: mongo.DefaultSource\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "# load all data from MongoDB\n",
    "df_ratings = spark.read.format(\"mongo\")\\\n",
    "    .option(\"uri\", \"mongodb://127.0.0.1:27017/\")\\\n",
    "    .option(\"database\", \"test\")\\\n",
    "    .option(\"collection\", \"ratings\")\\\n",
    "    .load()    \n",
    "\n",
    "df_movies = spark.read.format(\"mongo\")\\\n",
    "    .option(\"uri\", \"mongodb://127.0.0.1:27017/test.movies\")\\\n",
    "    .option(\"database\", \"test\")\\\n",
    "    .option(\"collection\", \"movies\")\\\n",
    "    .load()   \n",
    "\n",
    "# Show the loaded data\n",
    "print(f\"Original Rating Data:\")\n",
    "print(df_ratings.show())\n",
    "print(f\"Original Movie Data:\")\n",
    "print( df_movies.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make query to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query sent to MongoDB: {\"rating\": {\"$gt\": 4}}\n",
      "Filtered Data (movies with rating > 4):\n",
      "+--------------------+-------+------+---------+------+\n",
      "|                 _id|movieId|rating|timestamp|userId|\n",
      "+--------------------+-------+------+---------+------+\n",
      "|{6743f02df2b2062a...|      1|   4.0|964982703|     1|\n",
      "|{6743f02df2b2062a...|      3|   4.0|964981247|     1|\n",
      "|{6743f02df2b2062a...|      6|   4.0|964982224|     1|\n",
      "|{6743f02df2b2062a...|     47|   5.0|964983815|     1|\n",
      "|{6743f02df2b2062a...|     50|   5.0|964982931|     1|\n",
      "|{6743f02df2b2062a...|     70|   3.0|964982400|     1|\n",
      "|{6743f02df2b2062a...|    101|   5.0|964980868|     1|\n",
      "|{6743f02df2b2062a...|    110|   4.0|964982176|     1|\n",
      "|{6743f02df2b2062a...|    151|   5.0|964984041|     1|\n",
      "|{6743f02df2b2062a...|    157|   5.0|964984100|     1|\n",
      "|{6743f02df2b2062a...|    163|   5.0|964983650|     1|\n",
      "|{6743f02df2b2062a...|    216|   5.0|964981208|     1|\n",
      "|{6743f02df2b2062a...|    223|   3.0|964980985|     1|\n",
      "|{6743f02df2b2062a...|    231|   5.0|964981179|     1|\n",
      "|{6743f02df2b2062a...|    235|   4.0|964980908|     1|\n",
      "|{6743f02df2b2062a...|    260|   5.0|964981680|     1|\n",
      "|{6743f02df2b2062a...|    296|   3.0|964982967|     1|\n",
      "|{6743f02df2b2062a...|    316|   3.0|964982310|     1|\n",
      "|{6743f02df2b2062a...|    333|   5.0|964981179|     1|\n",
      "|{6743f02df2b2062a...|    349|   4.0|964982563|     1|\n",
      "+--------------------+-------+------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sol 1: failed, maybe because of the version of the spark\n",
    "query = '{\"rating\": {\"$gt\": 4}}'\n",
    "print(f\"Query sent to MongoDB: {query}\")\n",
    "\n",
    "# Load filtered data\n",
    "df_ratings_filtered = spark.read.format(\"mongo\")\\\n",
    "    .option(\"uri\", \"mongodb://127.0.0.1:27017/\")\\\n",
    "    .option(\"database\", \"test\")\\\n",
    "    .option(\"collection\", \"ratings\")\\\n",
    "    .option(\"query\", query)\\\n",
    "    .load()\n",
    "\n",
    "# Show filtered data\n",
    "print(\"Filtered Data (movies with rating > 4):\")\n",
    "df_ratings_filtered.show()\n",
    "query = '{\"rating\": {\"$gt\": 4}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.21632814407348633 seconds\n"
     ]
    }
   ],
   "source": [
    "# set format as \"mongo\" instead of \"mongodb\", set uri\n",
    "start_time = time.time()\n",
    "df_ratings_filtered = spark.read.format(\"mongo\").option(\"uri\", \"mongodb://127.0.0.1:27017/\") \\\n",
    "                 .option(\"database\", \"test\") \\\n",
    "                 .option(\"collection\", \"ratings\") \\\n",
    "                 .load()\n",
    "\n",
    "df_ratings_filtered.filter(df_ratings_filtered['rating'] > 4)\n",
    "end_time = time.time()\n",
    "df_ratings_filtered.head()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  userId  movieId  rating  timestamp\n",
      "0  6743f02df2b2062a22ecadae       1       47     5.0  964983815\n",
      "1  6743f02df2b2062a22ecadaf       1       50     5.0  964982931\n",
      "2  6743f02df2b2062a22ecadb1       1      101     5.0  964980868\n",
      "3  6743f02df2b2062a22ecadb3       1      151     5.0  964984041\n",
      "4  6743f02df2b2062a22ecadb4       1      157     5.0  964984100\n",
      "Time taken to fetch data from MongoDB: 0.0040130615234375\n",
      "Total time taken: 0.9110825061798096\n"
     ]
    }
   ],
   "source": [
    "# sol 2: return cursors points to rows in the collection\n",
    "start_time = time.time()\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client[\"test\"]\n",
    "collection = db[\"ratings\"]\n",
    "\n",
    "query = {\"rating\": {\"$gt\": 4}}  # Find documents where age > 25\n",
    "cursors = collection.find(query)\n",
    "\n",
    "# for doc in results:\n",
    "#     print(doc)\n",
    "\n",
    "stop_time1 = time.time()\n",
    "\n",
    "filtered_df = pd.DataFrame(list(cursors))\n",
    "stop_time = time.time()\n",
    "print(filtered_df.head())\n",
    "print(f\"Time taken to fetch data from MongoDB: {stop_time1 - start_time}\")\n",
    "print(f\"Total time taken: {stop_time - start_time}\")\n",
    "# cursors = list(cursors)\n",
    "# print(cursors[0]['userId', 'movieId', 'rating', 'timestamp'])\n",
    "\n",
    "# filtered_df = spark.createDataFrame(list(cursors))\n",
    "# filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 19.08342432975769\n"
     ]
    }
   ],
   "source": [
    "# sol 3: get the dataframe, then filter it using pandas => worse than using MongoDB query\n",
    "start_time = time.time()\n",
    "df_ratings = spark.read.format(\"mongo\")\\\n",
    "    .option(\"uri\", \"mongodb://127.0.0.1:27017/test.ratings\")\\\n",
    "    .load()\n",
    "\n",
    "df_ratings_pd = df_ratings.toPandas()\n",
    "df_ratings_pd = df_ratings_pd[df_ratings_pd['rating'] > 4]\n",
    "\n",
    "df_ratings_pd.head()\n",
    "stop_time = time.time()\n",
    "print(f\"Time taken: {stop_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark's dataframe operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies_ratings_df:\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+------+---------+------+\n",
      "|movieId|                 _id|              genres|               title|                 _id|rating|timestamp|userId|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+------+---------+------+\n",
      "|      1|{6743f02df2b2062a...|Adventure|Animati...|    Toy Story (1995)|{6743f02df2b2062a...|   4.0|964982703|     1|\n",
      "|      1|{674450be3c85934c...|Adventure|Animati...|    Toy Story (1995)|{6743f02df2b2062a...|   4.0|964982703|     1|\n",
      "|      1|{67450b9460d4f003...|Adventure|Animati...|    Toy Story (1995)|{6743f02df2b2062a...|   4.0|964982703|     1|\n",
      "|      1|{6745127b01820ef6...|Adventure|Animati...|    Toy Story (1995)|{6743f02df2b2062a...|   4.0|964982703|     1|\n",
      "|      3|{6743f02df2b2062a...|      Comedy|Romance|Grumpier Old Men ...|{6743f02df2b2062a...|   4.0|964981247|     1|\n",
      "|      3|{674450be3c85934c...|      Comedy|Romance|Grumpier Old Men ...|{6743f02df2b2062a...|   4.0|964981247|     1|\n",
      "|      3|{67450b9460d4f003...|      Comedy|Romance|Grumpier Old Men ...|{6743f02df2b2062a...|   4.0|964981247|     1|\n",
      "|      3|{6745127b01820ef6...|      Comedy|Romance|Grumpier Old Men ...|{6743f02df2b2062a...|   4.0|964981247|     1|\n",
      "|      6|{6743f02df2b2062a...|Action|Crime|Thri...|         Heat (1995)|{6743f02df2b2062a...|   4.0|964982224|     1|\n",
      "|      6|{674450be3c85934c...|Action|Crime|Thri...|         Heat (1995)|{6743f02df2b2062a...|   4.0|964982224|     1|\n",
      "|      6|{67450b9460d4f003...|Action|Crime|Thri...|         Heat (1995)|{6743f02df2b2062a...|   4.0|964982224|     1|\n",
      "|      6|{6745127b01820ef6...|Action|Crime|Thri...|         Heat (1995)|{6743f02df2b2062a...|   4.0|964982224|     1|\n",
      "|     47|{6743f02df2b2062a...|    Mystery|Thriller|Seven (a.k.a. Se7...|{6743f02df2b2062a...|   5.0|964983815|     1|\n",
      "|     47|{674450be3c85934c...|    Mystery|Thriller|Seven (a.k.a. Se7...|{6743f02df2b2062a...|   5.0|964983815|     1|\n",
      "|     47|{67450b9460d4f003...|    Mystery|Thriller|Seven (a.k.a. Se7...|{6743f02df2b2062a...|   5.0|964983815|     1|\n",
      "|     47|{6745127b01820ef6...|    Mystery|Thriller|Seven (a.k.a. Se7...|{6743f02df2b2062a...|   5.0|964983815|     1|\n",
      "|     50|{6743f02df2b2062a...|Crime|Mystery|Thr...|Usual Suspects, T...|{6743f02df2b2062a...|   5.0|964982931|     1|\n",
      "|     50|{674450be3c85934c...|Crime|Mystery|Thr...|Usual Suspects, T...|{6743f02df2b2062a...|   5.0|964982931|     1|\n",
      "|     50|{67450b9460d4f003...|Crime|Mystery|Thr...|Usual Suspects, T...|{6743f02df2b2062a...|   5.0|964982931|     1|\n",
      "|     50|{6745127b01820ef6...|Crime|Mystery|Thr...|Usual Suspects, T...|{6743f02df2b2062a...|   5.0|964982931|     1|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_movies.show()\n",
    "# df_ratings.show()\n",
    "\n",
    "joined_df = df_movies.join(df_ratings, on=\"movieId\", how=\"right\")\n",
    "print(f\"movies_ratings_df:\")\n",
    "# print(joined_df.columns)\n",
    "# print(joined_df.select(\"timestamp\").show())\n",
    "# print(type(joined_df))\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column named \"Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+------+----------+------+----+\n",
      "|movieId|                 _id|              genres|               title|                 _id|rating| timestamp|userId|year|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+------+----------+------+----+\n",
      "|   1580|{6745127b01820ef6...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 964981125|     1|1997|\n",
      "|   1580|{67450b9460d4f003...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 964981125|     1|1997|\n",
      "|   1580|{674450be3c85934c...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 964981125|     1|1997|\n",
      "|   1580|{6743f02df2b2062a...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 964981125|     1|1997|\n",
      "|   2366|{6745127b01820ef6...|Action|Adventure|...|    King Kong (1933)|{6743f02df2b2062a...|   4.0| 964982462|     1|1933|\n",
      "|   2366|{67450b9460d4f003...|Action|Adventure|...|    King Kong (1933)|{6743f02df2b2062a...|   4.0| 964982462|     1|1933|\n",
      "|   2366|{674450be3c85934c...|Action|Adventure|...|    King Kong (1933)|{6743f02df2b2062a...|   4.0| 964982462|     1|1933|\n",
      "|   2366|{6743f02df2b2062a...|Action|Adventure|...|    King Kong (1933)|{6743f02df2b2062a...|   4.0| 964982462|     1|1933|\n",
      "|   1580|{6745127b01820ef6...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 986935244|     4|1997|\n",
      "|   1580|{67450b9460d4f003...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 986935244|     4|1997|\n",
      "|   1580|{674450be3c85934c...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 986935244|     4|1997|\n",
      "|   1580|{6743f02df2b2062a...|Action|Comedy|Sci-Fi|Men in Black (a.k...|{6743f02df2b2062a...|   3.0| 986935244|     4|1997|\n",
      "|   3175|{6745127b01820ef6...|Adventure|Comedy|...| Galaxy Quest (1999)|{6743f02df2b2062a...|   1.0| 964538930|     4|1999|\n",
      "|   3175|{67450b9460d4f003...|Adventure|Comedy|...| Galaxy Quest (1999)|{6743f02df2b2062a...|   1.0| 964538930|     4|1999|\n",
      "|   3175|{674450be3c85934c...|Adventure|Comedy|...| Galaxy Quest (1999)|{6743f02df2b2062a...|   1.0| 964538930|     4|1999|\n",
      "|   3175|{6743f02df2b2062a...|Adventure|Comedy|...| Galaxy Quest (1999)|{6743f02df2b2062a...|   1.0| 964538930|     4|1999|\n",
      "|   1088|{6745127b01820ef6...|Drama|Musical|Rom...|Dirty Dancing (1987)|{6743f02df2b2062a...|   3.0|1455619275|    10|1987|\n",
      "|   1088|{67450b9460d4f003...|Drama|Musical|Rom...|Dirty Dancing (1987)|{6743f02df2b2062a...|   3.0|1455619275|    10|1987|\n",
      "|   1088|{674450be3c85934c...|Drama|Musical|Rom...|Dirty Dancing (1987)|{6743f02df2b2062a...|   3.0|1455619275|    10|1987|\n",
      "|   1088|{6743f02df2b2062a...|Drama|Musical|Rom...|Dirty Dancing (1987)|{6743f02df2b2062a...|   3.0|1455619275|    10|1987|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+------+----------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "joined_df = joined_df.withColumn(\"year\", substring(\"title\", -5, 4))\n",
    "joined_df = joined_df.filter(col(\"year\").rlike(\"^[12]\"))\n",
    "joined_df = joined_df.withColumn(\"year\", col(\"year\").cast(\"int\"))\n",
    "\n",
    "joined_df.show()\n",
    "# joined_df.select(\"year\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a movie recommender model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommender = RecommendationEngine(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_assembler = VectorAssembler(inputCols=[\"userId\", \"movieId\"], outputCol=\"features\")\n",
    "assembled_df = feature_assembler.transform(joined_df)\n",
    "(training_data, test_data) = assembled_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "lr_model = model.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------+\n",
      "|    features|rating|        prediction|\n",
      "+------------+------+------------------+\n",
      "| [19.0,12.0]|   1.0|3.5889894264465667|\n",
      "| [44.0,12.0]|   1.0|  3.58205064574231|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[571.0,12.0]|   1.0|3.4357811484965803|\n",
      "| [44.0,12.0]|   1.0|  3.58205064574231|\n",
      "|[151.0,12.0]|   3.0|3.5523526643280916|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[524.0,12.0]|   1.0| 3.448826056220583|\n",
      "| [19.0,12.0]|   1.0|3.5889894264465667|\n",
      "|[217.0,12.0]|   3.0|3.5340342832688543|\n",
      "|[274.0,12.0]|   3.5| 3.518213863263149|\n",
      "|[524.0,12.0]|   1.0| 3.448826056220583|\n",
      "|[599.0,12.0]|   1.5| 3.428009714107813|\n",
      "|[276.0,12.0]|   4.0|3.5176587608068086|\n",
      "|[288.0,12.0]|   2.0|3.5143281460687654|\n",
      "|[571.0,12.0]|   1.0|3.4357811484965803|\n",
      "|[217.0,12.0]|   3.0|3.5340342832688543|\n",
      "|[288.0,12.0]|   2.0|3.5143281460687654|\n",
      "|[294.0,12.0]|   1.0| 3.512662838699744|\n",
      "|[350.0,12.0]|   3.0| 3.497119969922209|\n",
      "+------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE): 1.0392742649810824\n",
      "R2: 0.0026706517185250966\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# show predictions\n",
    "predictions.select(\"features\", \"rating\", \"prediction\").show()\n",
    "\n",
    "# evaluate the model using R2 and RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "evaluator.setMetricName(\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.546270888146419\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "ratings = joined_df.select(\"userId\", \"movieId\", \"rating\")\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "\n",
    "# set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# evaluate\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n",
    "\n",
    "# top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "\n",
    "# top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{3925, 6.7853904...|\n",
      "|     2|[{74754, 7.789781...|\n",
      "|     3|[{48322, 6.951864...|\n",
      "|     4|[{34338, 7.271497...|\n",
      "|     5|[{5034, 6.932786}...|\n",
      "|     6|[{971, 7.036011},...|\n",
      "|     7|[{4678, 9.650388}...|\n",
      "|     8|[{5055, 7.2378206...|\n",
      "|     9|[{106100, 7.42635...|\n",
      "|    10|[{2693, 8.148736}...|\n",
      "|    11|[{3200, 6.935401}...|\n",
      "|    12|[{26258, 8.614412...|\n",
      "|    13|[{2148, 7.473914}...|\n",
      "|    14|[{2906, 11.770087...|\n",
      "|    15|[{1734, 7.8901587...|\n",
      "|    16|[{3925, 5.546985}...|\n",
      "|    17|[{1658, 6.442111}...|\n",
      "|    18|[{3200, 5.1955605...|\n",
      "|    19|[{5666, 5.1309776...|\n",
      "|    20|[{179819, 7.15204...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(userRecs.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   463|[{79224, 7.039547...|\n",
      "|   496|[{34338, 9.542832...|\n",
      "|   148|[{4450, 7.3070965...|\n",
      "+------+--------------------+\n",
      "\n",
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|   463|\n",
      "|   496|\n",
      "|   148|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.show()\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[{569, 5.2485666}...|\n",
      "|   3175|[{258, 6.324589},...|\n",
      "|   2366|[{494, 7.989951},...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieSubSetRecs.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
